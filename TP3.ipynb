{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21d8c91d-0484-4db4-a0b1-344e54d6ea7b",
   "metadata": {},
   "source": [
    "# Lab 3: Querying RDF graphs using SPQRQL and Entity linking\n",
    "\n",
    "\n",
    "## Wikidata and its SPARQL endpoint\n",
    "\n",
    "Wikidata is an RDF dataset that contains knowledge about the world. Wikidata is a **knowledge graph**,\n",
    "similar to the Google Knowledge Graph we discussed during the lectures (used by Google to show the\n",
    "information on the right displayed when querying certain information, such as people). It works similarly to\n",
    "Wikipedia, that is volunteers are inserting high-quality information, in addition to scripts that might add\n",
    "some simpler data.\n",
    "Check the following resources and properties present on Wikidata:\n",
    "- https://www.wikidata.org/wiki/Q1\n",
    "- https://www.wikidata.org/wiki/Q2\n",
    "- https://www.wikidata.org/wiki/Q3 (the indexes Q1, Q2, . . . organize resources according to their\n",
    "importance, but not only)\n",
    "- https://www.wikidata.org/wiki/Q666\n",
    "- https://www.wikidata.org/wiki/Wikidata:List_of_properties/all_in_one_table\n",
    "\n",
    "\n",
    "In this lab we will follow a tutorial, which in addition to introducing Wikidata, it contains also a very\n",
    "good presentation of SPARQL, the query language used for extracting data from an RDF graph:\n",
    "\n",
    "https://www.wikidata.org/wiki/Wikidata:SPARQL_tutorial\n",
    "\n",
    "After you completed the tutorial, check the list of query examples present here: \n",
    "https://www.wikidata.org/wiki/Wikidata:SPARQL_query_service/queries/examples\n",
    "\n",
    "\n",
    "**Exercise 1** Formulate a question that could be answered using Wikidata based on your interests and write the SPARQL code for it and run it on the SPARQL endpoint of Wikidata. Note that it is very likely you will use Wikidata for your project, so make sure you understand the main concepts in SPARQL. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "fb532a25-5ec8-4fe0-8af3-40f2509ccaae",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# save your queries here\n",
    "\n",
    "#Requete 1\n",
    "SELECT ?job ?jobLabel\n",
    "WHERE\n",
    "{\n",
    "  wd:Q15935 wdt:P106 ?job.\n",
    "  wd:Q173637 wdt:P106 ?job.\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE]\". }\n",
    "  \n",
    "}\n",
    "\n",
    "#Requete 2\n",
    "SELECT ?job ?jobLabel\n",
    "WHERE\n",
    "{\n",
    "  wd:Q15935 wdt:P40 ?job.\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE]\". }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a2c57a-70eb-4520-b980-ac65eca01cfa",
   "metadata": {},
   "source": [
    "## Querying BnF data\n",
    "We propose to look at the data shared by BnF. As with Wikidata, there is an online SPARQL endpoint for BnF: http://data.bnf.fr/sparql/ \n",
    "Answer the following questions. Pay attention, it is desirable to limit the number of data points returned, using the keyword LIMIT.\n",
    "\n",
    "Check:\n",
    "- What types of publications are available?\n",
    "- What information is stored on the works?\n",
    "- What information is stored on the writers?\n",
    "\n",
    "For this, look at this description https://data.bnf.fr/images/modele_donnees_2018_02.pdf and try queries using this tutorial:\n",
    "https://www.biblibre.com/fr/blog/comment-interroger-la-bnf-et-wikidata-avec-sparql/\n",
    "Note that when you try the query on the \"The hitch hiker's guide to the galaxy\", you can find the equivalent work in Wikidata, under the property owl#sameAs. \n",
    "\n",
    "**Exercise 2** Using this information, answer the following questions using SPARQL queries.\n",
    "- Are there works published after 2000? If yes, find some examples.\n",
    "- Are there any works published before 1800? If yes, find some examples.\n",
    "- Who are the authors who published novels in the 21st century? Return their city if possible.\n",
    "- Who are the authors alive that have published at least one book in the last 20 years?\n",
    "- How many authors have published a book in the 19th century?\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2466e5b-d33e-435b-a005-bd5cc7388f81",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# save your queries here\n",
    "#1\n",
    "PREFIX frbr-rda: <http://rdvocab.info/uri/schema/FRBRentitiesRDA/>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdagroup1elements: <http://rdvocab.info/Elements/>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "SELECT DISTINCT ?p ?Concept ?date ?dateLabel\n",
    "WHERE {\n",
    "  ?p a ?Concept.\n",
    "  ?p rdf:type frbr-rda:Work.\n",
    "  ?p rdagroup1elements:dateOfWork ?date.\n",
    "  ?date rdfs:label ?dateLabel .\n",
    "  FILTER(\"2000\"^^<http://www.w3.org/2001/XMLSchema#integer> <= ?dateLabel).\n",
    "} LIMIT 100\n",
    "\n",
    "#examples : Bowling alone, The pledge (film), Rayman M (jeu vidÃ©o)\n",
    "\n",
    "#2\n",
    "PREFIX frbr-rda: <http://rdvocab.info/uri/schema/FRBRentitiesRDA/>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdagroup1elements: <http://rdvocab.info/Elements/>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "SELECT DISTINCT ?p ?Concept ?name ?date ?dateLabel \n",
    "WHERE {\n",
    "  ?p a ?Concept.\n",
    "  ?p rdf:type frbr-rda:Work.\n",
    "  ?p rdfs:label ?name.\n",
    "  ?p rdagroup1elements:dateOfWork ?date.\n",
    "  ?date rdfs:label ?dateLabel .\n",
    "  FILTER(\"1800\"^^<http://www.w3.org/2001/XMLSchema#integer> >= ?dateLabel).\n",
    "}\n",
    "#ORDER BY DESC(?date)\n",
    "LIMIT 100\n",
    "#examples : Catholicon (1286), Visio Alberici (1127)\n",
    "\n",
    "#3\n",
    "PREFIX rdagroup2elements: <http://rdvocab.info/ElementsGr2/>\n",
    "PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n",
    "PREFIX dcterms: <http://purl.org/dc/terms/>\n",
    "PREFIX frbr-rda: <http://rdvocab.info/uri/schema/FRBRentitiesRDA/>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdagroup1elements: <http://rdvocab.info/Elements/>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "SELECT DISTINCT ?author_name ?city\n",
    "WHERE {\n",
    "  ?p a ?Concept.\n",
    "  ?p rdf:type frbr-rda:Work.\n",
    "  ?p rdfs:label ?name.\n",
    "  ?p dcterms:creator ?author.\n",
    "  ?author foaf:name ?author_name.\n",
    "  ?author rdagroup2elements:placeOfBirth ?city.\n",
    "\n",
    "  ?p rdagroup1elements:dateOfWork ?date.\n",
    "  ?date rdfs:label ?dateLabel .\n",
    "  FILTER(\"2000\"^^<http://www.w3.org/2001/XMLSchema#integer> <= ?dateLabel).\n",
    "} LIMIT 100\n",
    "\n",
    "#4\n",
    "PREFIX bio: <http://vocab.org/bio/0.1/>\n",
    "PREFIX rdagroup2elements: <http://rdvocab.info/ElementsGr2/>\n",
    "PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n",
    "PREFIX dcterms: <http://purl.org/dc/terms/>\n",
    "PREFIX frbr-rda: <http://rdvocab.info/uri/schema/FRBRentitiesRDA/>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdagroup1elements: <http://rdvocab.info/Elements/>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "SELECT DISTINCT ?author_name\n",
    "WHERE {\n",
    "  #Selection des oeuvres\n",
    "  ?p a ?Concept.\n",
    "  ?p rdf:type frbr-rda:Work.\n",
    "  ?p rdfs:label ?name_book.\n",
    "  \n",
    "  #Recuperation de l'auteur et de sa date de mort. On verifie qu'il est encore vivant\n",
    "  ?p dcterms:creator ?author.\n",
    "  ?author foaf:name ?author_name.\n",
    "  \n",
    "  #On regarde les auteurs encore en vie\n",
    "  OPTIONAL{?author bio:death ?death}\n",
    "  BIND(IF(BOUND(?death), \"1\", \"0\") AS ?var).\n",
    "  FILTER(?var = \"0\").\n",
    "  \n",
    "  #On regarde que l'oeuvre a ete publiee il y a moins de 20 ans\n",
    "  ?p rdagroup1elements:dateOfWork ?date.\n",
    "  ?date rdfs:label ?dateLabel .\n",
    "  FILTER(\"2005\"^^<http://www.w3.org/2001/XMLSchema#integer> <= ?dateLabel).\n",
    "} LIMIT 100\n",
    "\n",
    "#5\n",
    "PREFIX bio: <http://vocab.org/bio/0.1/>\n",
    "PREFIX rdagroup2elements: <http://rdvocab.info/ElementsGr2/>\n",
    "PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n",
    "PREFIX dcterms: <http://purl.org/dc/terms/>\n",
    "PREFIX frbr-rda: <http://rdvocab.info/uri/schema/FRBRentitiesRDA/>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdagroup1elements: <http://rdvocab.info/Elements/>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "SELECT DISTINCT (COUNT(DISTINCT ?author) AS ?nb)\n",
    "WHERE {\n",
    "  #Selection des oeuvres\n",
    "  ?p a ?Concept.\n",
    "  ?p rdf:type frbr-rda:Work.\n",
    "  ?p rdfs:label ?name_book.\n",
    "  \n",
    "  #Recuperation de l'auteur\n",
    "  ?p dcterms:creator ?author.\n",
    "  ?author foaf:name ?author_name.\n",
    "  \n",
    "  #On regarde que l'oeuvre a ete publiee au 19eme siecle\n",
    "  ?p rdagroup1elements:dateOfWork ?date.\n",
    "  ?date rdfs:label ?dateLabel .\n",
    "  FILTER(\"1800\"^^<http://www.w3.org/2001/XMLSchema#integer> <= ?dateLabel && \"1899\"^^<http://www.w3.org/2001/XMLSchema#integer> >= ?dateLabel).\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659de996-58d0-4449-bde8-996f32b75840",
   "metadata": {},
   "source": [
    "## Equivalence Links in RDF\n",
    "As discussed during the class and also seen in the previous exercise, in OWL, it is possible to express that two entities, two classes or two properties are equivalent. \n",
    "\n",
    "- If r_1 **owl:sameAs** r_2, for two resources r_1,r_2, \n",
    "it implies that r_1 is the same resource as r_2 and therefore they should be treated such as.\n",
    "-  If p_1 **owl:equivalentProperty** p_2 for two properties p_1,p_2,\n",
    "it implies that p_1 is the same property as p_2 and then they should be treated such as.\n",
    "-  If c_1 **owl:equivalentClass** c_2 for two classes c_1,c_2, \n",
    "it implies that c_1 is the same class as c_2 and therefore they should be treated such as.\n",
    "\n",
    "\n",
    "The website http://www.sameas.cc/ manages the matches between millions of links. \n",
    "\n",
    "**Exercise 3**\n",
    "In the SPARQL endpoint of the French version of DBPedia,  http://fr.dbpedia.org/sparqlEditor/index.html, find: 1) the resources linked by the property  *owl:sameAs*, 2) find the property linked by the property  *owl:equivalentProperty*, and 2) find the classes linked by the property  *owl:equivalentClass*. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "299c246e-c91a-4f89-a719-826e75ba0960",
   "metadata": {},
   "source": [
    "# save your results here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28f8572-be87-451d-9111-8d7212b78f26",
   "metadata": {},
   "source": [
    "**Exercise 4**\n",
    "Check different datasets containing information about Victor Hugo: DBPedia http://fr.dbpedia.org/page/Victor_Hugo, BNF https://data.bnf.fr/11907966/victor_hugo and Wikidata https://www.wikidata.org/wiki/Q535. Check which knowledge graph contains more properties of Victor Hugo. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b089161-698c-47de-aef7-7b929d876f04",
   "metadata": {},
   "source": [
    "# save your results here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ea9b29-cc7d-421d-9d81-bc31272d4f50",
   "metadata": {},
   "source": [
    "## Similarity functions for strings in Python\n",
    "\n",
    "**Exercise 5**\n",
    "Please check the jellyfish library https://pypi.org/project/jellyfish/ . Choose a word, for example, *lillois* and different variations of it with caps or changing the letters, for example *lilloise*. Compare the results of the different distances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a04a48-11f3-4950-b1ca-c1e5318fbe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db5a0b8-6882-4b37-b405-9c38ab7fd9f3",
   "metadata": {},
   "source": [
    "**Exercise 6**\n",
    "Please check the spacy library and in particular the part on word embeddings https://spacy.io/usage/linguistic-features#vectors-similarity . Note that vector embeddings are language dependent, so if you are working with English, you need to download and use the English package (*python -m spacy download en_core_web_lg*), while for French you need to use *python -m spacy download fr_core_news_lg*. Test the library by computing similarities between words or between sentences. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79096cbe-d136-4221-9224-9f492b69ab53",
   "metadata": {},
   "source": [
    "## Similarity between Entities\n",
    "\n",
    "First, we propose to look at how to match entities from different files.\n",
    "The goal is not to implement a particular algorithm, but that you propose your method in the context of our datasets.\n",
    "\n",
    "We propose to link the entities of two citation databases from two well-known websites  DBLP http://dblp.uni-trier.de and ACM https://dl.acm.org/ .\n",
    "You can find the files on the website https://dbs.uni-leipzig.de/research/projects/object_matching/benchmark_datasets_for_entity_resolution at the following address http://dbs.uni-leipzig.de/file/DBLP-ACM.zip .\n",
    "In this zip file, you will also find correct matches to compare your approach to the truth.\n",
    "\n",
    "To read these files, you can use the csv library of Python or pandas as you have seen in previous labs. Please note that you might need to use the encoding *latin-1*.\n",
    "\n",
    "**Exercise 7.**\n",
    "Propose an algorithm to compute similar entities in the two files. Compare your results with the correct matches file and compute the different measures (precision, recall, F1) to evaluate your algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c003bc8-99d8-43db-baeb-67ff7c91d4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution exercise 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c41c42d-e39a-4feb-82c4-0ad76be66ec0",
   "metadata": {},
   "source": [
    "## Similarity between nodes and tuples\n",
    "\n",
    "In this part, we propose you create an algorithm to link entities in an RDF graph to tuples in a CSV file. \n",
    "\n",
    "**Exercise.**\n",
    "Using the files  deputy.csv and deputy.nt from Moodle, find matches between the entities of the two files.\n",
    "The files gather data about French deputies and they are extracted from the website \n",
    " nosdeputes.fr https://github.com/regardscitoyens/nosdeputes.fr/blob/master/doc/api.md#liste-des-parlementaires and the RDF file from the French DBPedia website http://fr.dbpedia.org/sparqlEditor/index.html\n",
    "To read an RDF graph in Python, use this library https://rdflib.readthedocs.io/en/stable/#getting-started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c723aac-42d8-4d87-aa65-0b87af36df44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution exercise 8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
